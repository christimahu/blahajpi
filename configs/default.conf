# Default Configuration
# Standard settings for general use

# Dataset parameters
dataset = ../../data/examples/twitter_example.csv
sample-limit = 10000      # Moderate sample size

# Model training parameters
alpha = 0.0005            # Default regularization parameter
eta0 = 0.05               # Default learning rate
epochs = 10               # Default number of epochs
loss = log                # Logistic regression loss

# Feature extraction parameters
use-sublinear-tf = true   # Apply logarithmic scaling to term frequencies
max-df = 0.5              # Standard document frequency filtering
max-features = 20000      # Standard feature count
min-ngram = 1             # Include unigrams
max-ngram = 3             # Include up to trigrams

# Cross-validation parameters
cv-folds = 5              # Standard cross-validation

# Word cloud parameters
generate-word-clouds = true
positive-cloud-file = ../outputs/positive_wordcloud.txt
negative-cloud-file = ../outputs/negative_wordcloud.txt

# Model saving parameters
model-dir = ../models/default_model
