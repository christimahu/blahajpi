# Fast Model Configuration
# Optimized for quick development iterations and testing

# Dataset parameters
dataset = ../../data/examples/twitter_example.csv
sample-limit = 2000       # Small sample size for speed

# Model training parameters
alpha = 0.001             # Stronger regularization for simpler model
eta0 = 0.1                # Higher learning rate for faster convergence
epochs = 5                # Fewer epochs to train faster
loss = log                # Logistic regression loss

# Feature extraction parameters
use-sublinear-tf = true
max-df = 0.7              # Less strict document frequency filtering
max-features = 5000       # Fewer features for faster processing
min-ngram = 1             # Only unigrams and bigrams for simplicity
max-ngram = 2             # Limit to bigrams for faster feature extraction

# Cross-validation parameters
cv-folds = 3              # Fewer folds for faster cross-validation

# Word cloud parameters
generate-word-clouds = false  # Skip word cloud generation to save time

# Model saving parameters
model-dir = ../models/fast_model
